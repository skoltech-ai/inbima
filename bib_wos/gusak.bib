
@article{ WOS:000668966500009,
Author = {Gusak, J. and Daulbaev, T. and Ponomarev, E. and Cichocki, A. and
   Oseledets, I},
Title = {{Reduced-Order Modeling of Deep Neural Networks}},
Journal = {{COMPUTATIONAL MATHEMATICS AND MATHEMATICAL PHYSICS}},
Year = {{2021}},
Volume = {{61}},
Number = {{5}},
Pages = {{774-785}},
Month = {{MAY}},
Abstract = {{We introduce a new method for speeding up the inference of deep neural
   networks. It is somewhat inspired by the reduced-order modeling
   techniques for dynamical systems. The cornerstone of the proposed method
   is the maximum volume algorithm. We demonstrate efficiency on neural
   networks pre-trained on different datasets. We show that in many
   practical cases it is possible to replace convolutional layers with much
   smaller fully-connected layers with a relatively small drop in accuracy.}},
Publisher = {{PLEIADES PUBLISHING INC}},
Address = {{PLEIADES HOUSE, 7 W 54 ST, NEW YORK,  NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Gusak, J (Corresponding Author), Skolkovo Inst Sci \& Technol, Moscow, Russia.
   Gusak, J.; Daulbaev, T.; Ponomarev, E.; Cichocki, A.; Oseledets, I, Skolkovo Inst Sci \& Technol, Moscow, Russia.}},
DOI = {{10.1134/S0965542521050109}},
ISSN = {{0965-5425}},
EISSN = {{1555-6662}},
Keywords = {{acceleration of neural networks; MaxVol; machine learning; component
   analysis}},
Research-Areas = {{Mathematics; Physics}},
Web-of-Science-Categories  = {{Mathematics, Applied; Physics, Mathematical}},
Author-Email = {{y.gusak@skoltech.ru
   t.daulbaev@skoltech.ru}},
Funding-Acknowledgement = {{RFBRRussian Foundation for Basic Research (RFBR) {[}19-31-90172,
   20-31-90127]; Ministry of Education and Science of the Russian
   FederationMinistry of Education and Science, Russian Federation
   {[}14.756.31.0001]}},
Funding-Text = {{This study was supported by RFBR, project nos. 19-31-90172 and
   20-31-90127 (algorithm) and by the Ministry of Education and Science of
   the Russian Federation (grant 14.756.31.0001) (experiments).}},
Number-of-Cited-References = {{39}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Comput. Math. Math. Phys.}},
Doc-Delivery-Number = {{TC9OJ}},
Unique-ID = {{WOS:000668966500009}},
OA = {{Green Submitted}},
DA = {{2021-10-27}},
}

@article{ WOS:000646588300007,
Author = {Cui, Chunfeng and Zhang, Kaiqi and Daulbaev, Talgat and Gusak, Julia and
   Oseledets, Ivan and Zhang, Zheng},
Title = {{Active Subspace of Neural Networks: Structural Analysis and Universal
   Attacks}},
Journal = {{SIAM JOURNAL ON MATHEMATICS OF DATA SCIENCE}},
Year = {{2020}},
Volume = {{2}},
Number = {{4}},
Pages = {{1096-1122}},
Abstract = {{Active subspace is a model reduction method widely used in the
   uncertainty quantification community. In this paper, we propose
   analyzing the internal structure and vulnerability of deep neural
   networks using active subspace. Firstly, we employ the active subspace
   to measure the number of ``active neurons{''}{''} at each intermediate
   layer, which indicates that the number of neurons can be reduced from
   several thousands to several dozens. This motivates us to change the
   network structure and to develop a new and more compact network,
   referred to as ASNet, that has significantly fewer model parameters.
   Secondly, we propose analyzing the vulnerability of a neural network
   using active subspace by finding an additive universal adversarial
   attack vector that can misclassify a dataset with a high probability.
   Our experiments on CIFAR-10 show that ASNet can achieve 23.98x parameter
   and 7.30x flops reduction. The universal active subspace attack vector
   can achieve around 20\% higher attack ratio compared with the existing
   approaches in our numerical experiments. The PyTorch codes for this
   paper are available online.}},
Publisher = {{SIAM PUBLICATIONS}},
Address = {{3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Cui, CF (Corresponding Author), Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
   Cui, Chunfeng; Zhang, Kaiqi; Zhang, Zheng, Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
   Daulbaev, Talgat; Gusak, Julia, Skolkovo Inst Sci \& Technol, Moscow, Russia.
   Oseledets, Ivan, Russian Acad Sci, Skolkovo Inst Sci \& Technol, Moscow, Russia.
   Oseledets, Ivan, Russian Acad Sci, Inst Numer Math, Moscow, Russia.}},
DOI = {{10.1137/19M1296070}},
EISSN = {{2577-0187}},
Keywords = {{active subspace; deep neural network; network reduction; universal
   adversarial perturbation}},
Research-Areas = {{Mathematics}},
Web-of-Science-Categories  = {{Mathematics, Applied}},
Author-Email = {{chunfengcui@ucsb.edu
   kzhang07@ucsb.edu
   talgat.daulbaev@skoltech.ru
   y.gusak@skoltech.ru
   ivan.oseledets@gamil.com
   zhengzhang@ece.ucsb.edu}},
Funding-Acknowledgement = {{UCSB start-up grant; Ministry of Education and Science of the Russian
   FederationMinistry of Education and Science, Russian Federation
   {[}14.756.31.0001]}},
Funding-Text = {{The work of the first, second, and sixth authors was supported by a UCSB
   start-up grant. The work of the third, fourth, and fifth authors was
   supported by the Ministry of Education and Science of the Russian
   Federation (grant 14.756.31.0001).}},
Number-of-Cited-References = {{59}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{SIAM J. Math. Data Sci.}},
Doc-Delivery-Number = {{RW5UO}},
Unique-ID = {{WOS:000646588300007}},
OA = {{Green Submitted, gold}},
DA = {{2021-10-27}},
}

@inproceedings{ WOS:000554591602068,
Author = {Gusak, Julia and Kholiavchenko, Maksym and Ponomarev, Evgeny and
   Markeeva, Larisa and Blagoveschensky, Philip and Cichocki, Andrzej and
   Oseledets, Ivan},
Book-Group-Author = {{IEEE}},
Title = {{Automated Multi-Stage Compression of Neural Networks}},
Booktitle = {{2019 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS
   (ICCVW)}},
Series = {{IEEE International Conference on Computer Vision Workshops}},
Year = {{2019}},
Pages = {{2501-2508}},
Note = {{IEEE/CVF International Conference on Computer Vision (ICCV), Seoul,
   SOUTH KOREA, OCT 27-NOV 02, 2019}},
Organization = {{IEEE; IEEE Comp Soc; CVF}},
Abstract = {{Low-rank tensor approximations are very promising for compression of
   deep neural networks. We propose a new simple and efficient iterative
   approach, which alternates low-rank factorization with smart rank
   selection and fine-tuning. We demonstrate the efficiency of our method
   comparing to non-iterative ones. Our approach improves the compression
   rate while maintaining the accuracy for a variety of tasks.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Gusak, J (Corresponding Author), Skolkovo Inst Sci \& Technol, Moscow, Russia.
   Gusak, Julia; Ponomarev, Evgeny; Markeeva, Larisa; Blagoveschensky, Philip; Cichocki, Andrzej; Oseledets, Ivan, Skolkovo Inst Sci \& Technol, Moscow, Russia.
   Kholiavchenko, Maksym, Innopolis Univ, Innopolis, Russia.
   Blagoveschensky, Philip, Huawei Noahs Ark Lab, Hong Kong, Peoples R China.}},
DOI = {{10.1109/ICCVW.2019.00306}},
ISSN = {{2473-9936}},
ISBN = {{978-1-7281-5023-9}},
Research-Areas = {{Computer Science; Imaging Science \& Photographic Technology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Imaging Science \& Photographic Technology}},
Author-Email = {{y.gusak@skoltec.ru
   m.kholyavchenko@innopolis.ru
   evgenii.ponomarev@skoltec.ru
   l.markeeva@skoltec.ru
   philip.blagoveschensky@skoltec.ru
   a.cichocki@skoltec.ru
   i.oseledets@skoltech.ru}},
Funding-Acknowledgement = {{Russian Science FoundationRussian Science Foundation (RSF)
   {[}17-12-01587]}},
Funding-Text = {{This work was supported by a grant of the Russian Science Foundation
   (Project No. 17-12-01587).}},
Number-of-Cited-References = {{26}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP4UH}},
Unique-ID = {{WOS:000554591602068}},
DA = {{2021-10-27}},
}

@inproceedings{ WOS:000460403300012,
Author = {Bulinskaya, Ekaterina and Gusak, Julia},
Editor = {{Pilz, J and Rasch, D and Melas, VB and Moder, K}},
Title = {{Insurance Models Under Incomplete Information}},
Booktitle = {{STATISTICS AND SIMULATION, IWS 8 2015}},
Series = {{Springer Proceedings in Mathematics \& Statistics}},
Year = {{2018}},
Volume = {{231}},
Pages = {{171-185}},
Note = {{8th International Workshop on Simulation, Univ Nat Resources \& Life
   Sci, Vienna, AUSTRIA, SEP 21-25, 2015}},
Organization = {{Univ Nat Resources \& Life Sci, Inst Appl Stat \& Comp, Ctr Expt Design;
   Alpen Adria Univ Klagenfurt, Dept Stat; St Petersburg State Univ, Dept
   Stat Modelling; INFORMS Simulat Soc}},
Abstract = {{The aim of the chapter is optimization of insurance company performance
   under incomplete information. To this end, we consider the
   periodic-review model with capital injections and reinsurance studied by
   the authors in their previous paper for the case of known claim
   distribution. We investigate the stability of the one-step and
   multi-step model in terms of the Kantorovich metric. These results are
   used for obtaining almost optimal policies based on the empirical
   distributions of underlying processes.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bulinskaya, E (Corresponding Author), Lomonosov Moscow State Univ, Moscow, Russia.
   Bulinskaya, Ekaterina; Gusak, Julia, Lomonosov Moscow State Univ, Moscow, Russia.}},
DOI = {{10.1007/978-3-319-76035-3\_12}},
ISSN = {{2194-1009}},
ISBN = {{978-3-319-76035-3; 978-3-319-76034-6}},
Keywords = {{Incomplete information; Periodic-review insurance model; Reinsurance;
   Capital injections; Optimization; Stability}},
Keywords-Plus = {{STRATEGIES}},
Research-Areas = {{Mathematics}},
Web-of-Science-Categories  = {{Mathematics; Statistics \& Probability}},
Author-Email = {{ebulinsk@yandex.ru}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{4}},
Doc-Delivery-Number = {{BM1QJ}},
Unique-ID = {{WOS:000460403300012}},
DA = {{2021-10-27}},
}
